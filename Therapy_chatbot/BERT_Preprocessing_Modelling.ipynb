{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "* https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py\n",
    "* https://peterbloem.nl/blog/transformers\n",
    "* https://arxiv.org/pdf/1810.04805\n",
    "* https://www.kaggle.com/code/chayan8/sentiment-analysis-using-bert-pytorch\n",
    "* https://github.com/curiousily/Getting-Things-Done-with-Pytorch/blob/master/3D_photo_inpainting.ipynb -> helpful examples\n",
    "* https://pytorch.org/hub/huggingface_pytorch-transformers/\n",
    "* https://medium.com/data-and-beyond/complete-guide-to-building-bert-model-from-sratch-3e6562228891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing new dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers datasets\n",
    "! pip install pytorch-transformers\n",
    "! pip install pandas seaborn matplotlib numpy\n",
    "! pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pytorch_lightning in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from pytorch_lightning) (1.24.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from pytorch_lightning) (2.3.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from pytorch_lightning) (4.66.4)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from pytorch_lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.3.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from pytorch_lightning) (1.4.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from pytorch_lightning) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from pytorch_lightning) (4.11.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from pytorch_lightning) (0.11.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (69.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=2.0.0->pytorch_lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=2.0.0->pytorch_lightning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=2.0.0->pytorch_lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=2.0.0->pytorch_lightning) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from torch>=2.0.0->pytorch_lightning) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from tqdm>=4.57.0->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->pytorch_lightning) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->pytorch_lightning) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from jinja2->torch>=2.0.0->pytorch_lightning) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from sympy->torch>=2.0.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch_lightning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy, F1Score, AUROC\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "# import libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn, optim\n",
    "import torchvision.transforms as transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels', 'id'],\n",
      "        num_rows: 43410\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels', 'id'],\n",
      "        num_rows: 5426\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'labels', 'id'],\n",
      "        num_rows: 5427\n",
      "    })\n",
      "})\n",
      "                                                text labels       id\n",
      "0  My favourite food is anything I didn't have to...   [27]  eebbqej\n",
      "1  Now if he does off himself, everyone will thin...   [27]  ed00q6i\n",
      "2                     WHY THE FUCK IS BAYLESS ISOING    [2]  eezlygj\n",
      "3                        To make her feel threatened   [14]  ed7ypvh\n",
      "4                             Dirty Southern Wankers    [3]  ed0bdzj\n",
      "Train dataset's shape: (43410, 3)\n",
      "Validation dataset's shape: (5426, 3)\n",
      "Test dataset's shape: (5427, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load the GoEmotions dataset\n",
    "datasets = load_dataset(\"go_emotions\")\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(datasets)\n",
    "train_df = pd.DataFrame(datasets['train'])\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"Train dataset's shape:\",datasets['train'].shape)\n",
    "print(\"Validation dataset's shape:\",datasets['validation'].shape)\n",
    "print(\"Test dataset's shape:\",datasets['test'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. GPU detected.\n",
      "Number of GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Properties of GPU 0: _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060 Laptop GPU', major=8, minor=6, total_memory=6143MB, multi_processor_count=30)\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL\n",
    "# checking if my GPU is ready to be used for training\n",
    "\n",
    "gpu_available = torch.cuda.is_available()\n",
    "\n",
    "if gpu_available:\n",
    "    print(\"CUDA is available. GPU detected.\")\n",
    "    # Get the number of GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs: {num_gpus}\")\n",
    "    # Print details about each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "        gpu_properties = torch.cuda.get_device_properties(i)\n",
    "        print(f\"Properties of GPU {i}: {gpu_properties}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPU detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing and training BERT\n",
    "### Overview steps:\n",
    "1. Encoding label into hot encoders \n",
    "2. Convert dataframe dictionary into dataframe using pandas\n",
    "3. Import BERT tokenizer to tokenize/encode the text \n",
    "5. Created tensor dataset with input ids (originally text), attention masks (from tokenizer/encoder), and label tensors (originally labels) \n",
    "6. Importing pre-trained pretrained BERT model to train machine\n",
    "7. Creatin optimizer and scheduler for training \n",
    "8. Setting up and checking GPU for training\n",
    "9. Train model and evaluate every epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Encode\n",
    "#### Description:\n",
    "BERT model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing \n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing data augumentation \n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "def synonym_replacement(text):\n",
    "    \n",
    "    words = text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        if synonyms:\n",
    "            synonym = random.choice(synonyms).lemmas()[0].name()\n",
    "            new_words.append(synonym)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(datasets['train'])\n",
    "df_validation = pd.DataFrame(datasets['validation'])\n",
    "df_test = pd.DataFrame(datasets['test'])\n",
    "\n",
    "# print(df_train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Labels:\n",
      " 0        ythi favourite to myself food 't i cook did ha...\n",
      "1        himself will if g ow everyo k screwi i off a s...\n",
      "2                           why isoi fuck the bayless g is\n",
      "3                              her to ed make threate feel\n",
      "4                                    kers souther dirty wa\n",
      "                               ...                        \n",
      "43405    hu aspect i’ve game well g what happily the i ...\n",
      "43406    ythi always to it was fu y refere ce g a but i...\n",
      "43407    ed [ ly good talki g that bad about what ythi ...\n",
      "43408                sexy baptism results with a like more\n",
      "43409                                       joy the ride e\n",
      "Name: clean_text, Length: 43410, dtype: object\n",
      "\n",
      "Train Labels Tensor:\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "\n",
      "Validation Labels Tensor:\n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "type_of_emotion = datasets['train'].features['labels'].feature.names\n",
    "\n",
    "# Function to encode numeric labels to multi-hot vectors \n",
    "def encode_labels(labels):\n",
    "    encoding = [0] * len(type_of_emotion)\n",
    "    for label in labels:\n",
    "        encoding[label] = 1\n",
    "    return encoding\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    sentences = re.sub(\"[.,!?-]\", '', text.lower()).split('n')  # filter '.', ',', '?', '!'\n",
    "    word_list = list(set(\" \".join(sentences).split()))\n",
    "    \n",
    "    return \" \".join(word_list)\n",
    "\n",
    "# Apply the encoding labels to the DataFrame\n",
    "df_train['encoded_labels'] = df_train['labels'].apply(encode_labels)\n",
    "df_validation['encoded_labels'] = df_validation['labels'].apply(encode_labels)\n",
    "#df_test['encoded_labels'] = df_test['labels'].apply(encode_labels)\n",
    "\n",
    "# Convert the labels to a list of lists\n",
    "labels_train_list = df_train['encoded_labels'].tolist()\n",
    "labels_validation_list = df_validation['encoded_labels'].tolist()\n",
    "#labels_test_list = df_test['encoded_labels'].tolist()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "labels_train_tensor = torch.tensor(labels_train_list, dtype=torch.float32)\n",
    "labels_validation_tensor = torch.tensor(labels_validation_list, dtype=torch.float32)\n",
    "#labels_test_tensor = torch.tensor(labels_test_list, dtype=torch.float32)\n",
    "\n",
    "df_train['clean_text'] = df_train['text'].apply(clean_text)\n",
    "df_validation['clean_text'] = df_validation['text'].apply(clean_text)\n",
    "\n",
    "# Print the resulting tensor to ensure correctness\n",
    "print(\"\\nTrain Labels:\\n\", df_train['clean_text'])\n",
    "print(\"\\nTrain Labels Tensor:\\n\", labels_train_tensor)\n",
    "print(\"\\nValidation Labels Tensor:\\n\", labels_validation_tensor)\n",
    "#print(\"\\nTest Labels Tensor:\\n\", labels_test_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\jessl\\AppData\\Local\\Temp\\ipykernel_43172\\2022630639.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(token_lens)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Token count')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in df_train.text:\n",
    "  tokens = tokenizer.encode(txt, max_length=512)\n",
    "  token_lens.append(len(tokens))\n",
    "     \n",
    "\n",
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 256])\n",
    "plt.xlabel('Token count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43410\n",
      "5426\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# creating data loaders\n",
    "# batch size reference https://huggingface.co/docs/transformers/model_doc/bert\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# implementing data augumentation \n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "def synonym_replacement(text):\n",
    "    \n",
    "    words = text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        if synonyms:\n",
    "            synonym = random.choice(synonyms).lemmas()[0].name()\n",
    "            new_words.append(synonym)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def random_insertion(text, n=2):\n",
    "    words = text.split()\n",
    "    for _ in range(n):\n",
    "        word = random.choice(words)\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        if synonyms:\n",
    "            synonym = random.choice(synonyms).lemmas()[0].name()\n",
    "            insert_index = random.randint(0, len(words) - 1)\n",
    "            words.insert(insert_index, synonym)\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        # Define how you want to apply augmentation\n",
    "        self.augment = lambda x: random.choice([synonym_replacement, random_insertion, random_deletion])(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        target = self.targets[idx]\n",
    "        augmented_text = self.augment(text)\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            augmented_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class EvaluationDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.float)  # Assuming target is a list or numpy array\n",
    "        }\n",
    "\n",
    "targets = len(type_of_emotion)\n",
    "max_len = 64\n",
    "train_dataset = EvaluationDataset(df_train.text, df_train['encoded_labels'], tokenizer, max_len)\n",
    "evaluate_dataset = AugmentedDataset(df_validation.text, df_validation['encoded_labels'], tokenizer, max_len)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(evaluate_dataset))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    num_workers=4, # subprocesses to use for data loading\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,  #data load will copy tensor to CUDA pinned memory before return (improve GPU stransfer speed)\n",
    "    prefetch_factor=2 # need google more\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    evaluate_dataset,\n",
    "    sampler=RandomSampler(evaluate_dataset),\n",
    "    batch_size=32,\n",
    "    num_workers=4, \n",
    "    pin_memory=True, \n",
    "    prefetch_factor=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df_train.clean_text.values,\n",
    "    add_special_tokens=True, # adding [CLS] and [SEP]\n",
    "    return_attention_mask=True, # change input to 1 with actual words and 0 to none\n",
    "    pad_to_max_length=True, \n",
    "    max_length=\t64,\n",
    "    return_token_type_ids=False, # length that is longer than max_length will be trucated\n",
    "    return_tensors='pt' # returning tensor in pytorch form\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df_validation.clean_text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=\t64,\n",
    "    return_token_type_ids=False, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  1061, 15222,  ...,     0,     0,     0],\n",
       "         [  101,  4756,  2111,  ...,     0,     0,     0],\n",
       "         [  101, 11163,  2072,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2054,  2020,  ...,     0,     0,     0],\n",
       "         [  101,  7916,  2066,  ...,     0,     0,     0],\n",
       "         [  101,  1041,  1996,  ...,     0,     0,     0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turning each dataset into tensor dataset to be processed\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, \n",
    "                              attention_masks_train,\n",
    "                              labels_train_tensor)\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val, \n",
    "                            attention_masks_val,\n",
    "                           labels_validation_tensor)\n",
    "\n",
    "dataset_train.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels, hidden_size=512, dropout_rate=0.3):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.lstm = nn.LSTM(self.bert.config.hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size * 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs[0]  # shape: (batch_size, sequence_length, hidden_size)\n",
    "        \n",
    "        lstm_output, _ = self.lstm(sequence_output)  # shape: (batch_size, sequence_length, hidden_size*2)\n",
    "        \n",
    "        # Use the mean of the LSTM output across the sequence length dimension\n",
    "        lstm_output_mean = torch.mean(lstm_output, dim=1)  # shape: (batch_size, hidden_size*2)\n",
    "        \n",
    "        lstm_output_mean = self.layer_norm(lstm_output_mean)  # shape: (batch_size, hidden_size*2)\n",
    "        lstm_output_mean = self.dropout(lstm_output_mean)  # shape: (batch_size, hidden_size*2)\n",
    "        \n",
    "        logits = self.classifier(lstm_output_mean)  # shape: (batch_size, num_labels)\n",
    "        probabilities = torch.sigmoid(logits)  # Use sigmoid for multi-label classification\n",
    "        \n",
    "        return logits, probabilities\n",
    "\n",
    "# Example initialization\n",
    "num_labels = len(type_of_emotion)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomBERTModel(num_labels=num_labels, hidden_size=256).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = BertForSequenceClassification.from_pretrained(\\n                                      'bert-base-uncased', \\n                                      num_labels = len(type_of_emotion),\\n                                      output_attentions = False,\\n                                      output_hidden_states = False\\n                                     )\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = BertForSequenceClassification.from_pretrained(\n",
    "                                      'bert-base-uncased', \n",
    "                                      num_labels = len(type_of_emotion),\n",
    "                                      output_attentions = False,\n",
    "                                      output_hidden_states = False\n",
    "                                     )'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data loaders\n",
    "# batch size reference https://huggingface.co/docs/transformers/model_doc/bert\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F \n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    num_workers=4, # subprocesses to use for data loading\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,  #data load will copy tensor to CUDA pinned memory before return (improve GPU stransfer speed)\n",
    "    prefetch_factor=2 # need google more\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=32,\n",
    "    num_workers=4, \n",
    "    pin_memory=True, \n",
    "    prefetch_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\jessl\\miniconda3\\envs\\torch_gpu_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# optimizer type: \n",
    "# Stochastic Gradient Descent (SGD): The basic optimization algorithm that updates parameters based on the gradient of the loss function.\n",
    "# Adam: A popular variant of SGD that combines adaptive learning rates with momentum.\n",
    "# AdamW: A variant of Adam that also incorporates weight decay to prevent overfitting.\n",
    "# Adagrad: Adapts the learning rate for each parameter based on the historical gradient information.\n",
    "# RMSprop: Root Mean Square Propagation, similar to Adagrad but with an exponentially decaying average of squared gradients.\n",
    "\n",
    "\n",
    "model = CustomBERTModel(num_labels = len(type_of_emotion))\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), # optimizing model\n",
    "    lr = 1e-5 ,\n",
    "    eps = 1e-8, # need a further verification\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "scaler= GradScaler()\n",
    "\n",
    "\n",
    "# Scheduler: a learning rate schediler that adjust learning rate during training to improve performance\n",
    "# type of scheduler:\n",
    "# StepLR: decreases the learning rate by a factor of the fized number of epochs\n",
    "# MultiStepLR: similar to StepLR but allows specifying multicle milestones for decreasing learning rate\n",
    "# ExponentialLR: decays the learning rate expotentially over time\n",
    "# Reduce LROnPlateau: decrease learning rate when specific metric stops improving -\n",
    "# CosineAnnealingLR: gradually decreases the learning rate base on cosine\n",
    "# Linear Warmup: linearly increases the learning rate from zero to the specified value over warmup period -\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage: 0%\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def get_gpu_usage():\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], stdout=subprocess.PIPE)\n",
    "        gpu_usage = int(result.stdout.decode('utf-8').strip())\n",
    "        return gpu_usage\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gpu_usage = get_gpu_usage()\n",
    "    if gpu_usage is not None:\n",
    "        print(f\"GPU Usage: {gpu_usage}%\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve GPU usage.\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "CustomBERTModel(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (lstm): LSTM(768, 512, batch_first=True, bidirectional=True)\n",
      "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=28, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# seeding / setting seeds for various random number to ensure that the result is the same\n",
    "seed_val = 17\n",
    "random.seed(seed_val) # sets seed for python's build in libraries\n",
    "np.random.seed(seed_val) # set seeds for numpy random generator\n",
    "torch.manual_seed(seed_val) # sets seed for pytorch CPU operations\n",
    "torch.cuda.manual_seed_all(seed_val) # set seeds for CUDA operation\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.cuda()\n",
    "print(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()  # sets model to evaluation mode, no dropout and batch normalization layer\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []  # to store predictions and true labels\n",
    "\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):  # iterate over batches of data in validation loader\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)  # move batch tensors to the appropriate device\n",
    "        \n",
    "        # prepare model inputs tensors \n",
    "        input_ids = batch[0]\n",
    "        attention_mask = batch[1]\n",
    "        labels = batch[2]\n",
    "        \n",
    "        # forward pass\n",
    "        # performing forward pass without gradient computation\n",
    "        with torch.no_grad():       \n",
    "            # passing input tensors to the model and obtain the outputs (loss and logits - raw output scores) \n",
    "            logits, probabilities = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            \n",
    "            # calculate raw values \n",
    "            loss_val_total += loss.item()\n",
    "\n",
    "            # processing predictions and true labels            \n",
    "            logits = logits.detach().cpu().numpy() # detach logits from computational graph -> to CPU -> to numpy array\n",
    "            label_ids = labels.detach().cpu().numpy() # same concept\n",
    "            \n",
    "        \n",
    "            # Ensure that the shapes are consistent before appending\n",
    "            if logits.shape[0] == label_ids.shape[0]:\n",
    "                predictions.append(logits)\n",
    "                true_vals.append(label_ids)\n",
    "            else:\n",
    "                print(f\"Shape mismatch: logits {logits.shape}, labels {label_ids.shape}\")\n",
    "    \n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    \n",
    "    # Debugging: Check the shapes before concatenation\n",
    "    # print(f\"Predictions shapes: {[pred.shape for pred in predictions]}\")\n",
    "    # print(f\"True values shapes: {[val.shape for val in true_vals]}\")\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    \n",
    "    # Final shape check\n",
    "    # print(f\"Final shape of predictions: {predictions.shape}\")\n",
    "    # print(f\"Final shape of true values: {true_vals.shape}\")\n",
    "    \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up performance metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    assert preds.shape[0] == labels.shape[0], f\"Shape mismatch: preds {preds.shape}, labels {labels.shape}\"\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.argmax(axis=1).flatten()\n",
    "    \n",
    "    # Check the shapes after flattening\n",
    "    # print(f\"Shapes after flattening - preds_flat: {preds_flat.shape}, labels_flat: {labels_flat.shape}\")\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in type_of_emotion.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/amp.html\n",
    "\n",
    "Libraries used for training:\n",
    "* tqdm: adding progress bars to loops so we can see training progress\n",
    "* GradScaler: dynamically adjust gradient scale before backward propagation. Ensuring that there is no overflow or underflow by rescalling them to similar as ROC curve (scale 0 to 1)  (https://youtu.be/IkeEadgSy6w)\n",
    "* Autocast: Automatic Mixed Precision (AMP) feature. Accelerate training by leveraging tensor cores on NVIDA GPUs. used around foward pass and loss calculation\n",
    "\n",
    "P.S. gradient scaler and autocast is just used when we want to utilize GPU for training\n",
    "Underflow:  value too small to represent or compute (close to zero)\n",
    "Overflow: values exceed numerical computations, causing memory leackage. can caused infinity\n",
    "\n",
    "underflow and overflow can cause numerical instabilities due numbers being too small and big, causing inaccurate computational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f99b89f381b45eaa7e7217954193226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457dfc027f224f68a2783199c3f04962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "epochs_to_save = [4, 6, 8, 10]\n",
    "\n",
    "save_dir = 'Models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_train, \n",
    "                        desc=f'Epoch {epoch}', \n",
    "                        leave=False, \n",
    "                        disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            logits, probabilities = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        # Scale gradients\n",
    "        scaler.scale(loss).backward()\n",
    "        # Update optimizer\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "       \n",
    "\n",
    "        loss_train_total += loss.item()\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "    \n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if epoch in epochs_to_save:\n",
    "        model_save_path = os.path.join(save_dir, f'BERT_ft_Epoch{epoch}.model')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
